{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc590a7e-09a3-43a1-b3d2-cdf94d5817e4",
   "metadata": {},
   "source": [
    "### BL.EN.U4AIE21054 G.Someswara reddy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4f38c4b5-3b06-4f16-aaf6-3f59c1dfe2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceca8bdc-e05a-4631-a0a4-3e56ae650f13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "756e68bb-c9ba-49e1-817a-17e76faf08f4",
   "metadata": {},
   "source": [
    "#### Question-1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d857176-6674-4f51-9a56-bf21577080ca",
   "metadata": {},
   "source": [
    "###  *A1. Use LSTM, Bi-LSTM networks for speech recognition. Use STFT / STCT, MFCC & LPC coefficients.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0ef7321f-36c7-40d5-b7a1-1fa6e180b4e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Akhileswar\\AppData\\Local\\Temp\\ipykernel_21284\\1903445273.py:41: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  y, sr = librosa.load(audio_file, sr=None)\n",
      "C:\\Users\\Akhileswar\\anaconda3\\Lib\\site-packages\\librosa\\core\\audio.py:183: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'speech_processing.wav'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLibsndfileError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\librosa\\core\\audio.py:175\u001b[0m, in \u001b[0;36mload\u001b[1;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 175\u001b[0m     y, sr_native \u001b[38;5;241m=\u001b[39m __soundfile_load(path, offset, duration, dtype)\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m sf\u001b[38;5;241m.\u001b[39mSoundFileRuntimeError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    178\u001b[0m     \u001b[38;5;66;03m# If soundfile failed, try audioread instead\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\librosa\\core\\audio.py:208\u001b[0m, in \u001b[0;36m__soundfile_load\u001b[1;34m(path, offset, duration, dtype)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    207\u001b[0m     \u001b[38;5;66;03m# Otherwise, create the soundfile object\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     context \u001b[38;5;241m=\u001b[39m sf\u001b[38;5;241m.\u001b[39mSoundFile(path)\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context \u001b[38;5;28;01mas\u001b[39;00m sf_desc:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\soundfile.py:658\u001b[0m, in \u001b[0;36mSoundFile.__init__\u001b[1;34m(self, file, mode, samplerate, channels, subtype, endian, format, closefd)\u001b[0m\n\u001b[0;32m    656\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info \u001b[38;5;241m=\u001b[39m _create_info_struct(file, mode, samplerate, channels,\n\u001b[0;32m    657\u001b[0m                                  \u001b[38;5;28mformat\u001b[39m, subtype, endian)\n\u001b[1;32m--> 658\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_open(file, mode_int, closefd)\n\u001b[0;32m    659\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mset\u001b[39m(mode)\u001b[38;5;241m.\u001b[39missuperset(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseekable():\n\u001b[0;32m    660\u001b[0m     \u001b[38;5;66;03m# Move write position to 0 (like in Python file objects)\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\soundfile.py:1216\u001b[0m, in \u001b[0;36mSoundFile._open\u001b[1;34m(self, file, mode_int, closefd)\u001b[0m\n\u001b[0;32m   1215\u001b[0m     err \u001b[38;5;241m=\u001b[39m _snd\u001b[38;5;241m.\u001b[39msf_error(file_ptr)\n\u001b[1;32m-> 1216\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LibsndfileError(err, prefix\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError opening \u001b[39m\u001b[38;5;132;01m{0!r}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname))\n\u001b[0;32m   1217\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode_int \u001b[38;5;241m==\u001b[39m _snd\u001b[38;5;241m.\u001b[39mSFM_WRITE:\n\u001b[0;32m   1218\u001b[0m     \u001b[38;5;66;03m# Due to a bug in libsndfile version <= 1.0.25, frames != 0\u001b[39;00m\n\u001b[0;32m   1219\u001b[0m     \u001b[38;5;66;03m# when opening a named pipe in SFM_WRITE mode.\u001b[39;00m\n\u001b[0;32m   1220\u001b[0m     \u001b[38;5;66;03m# See http://github.com/erikd/libsndfile/issues/77.\u001b[39;00m\n",
      "\u001b[1;31mLibsndfileError\u001b[0m: Error opening 'speech_processing.wav': System error.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 65\u001b[0m\n\u001b[0;32m     62\u001b[0m audio_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspeech_processing.wav\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;66;03m# Plot the signals\u001b[39;00m\n\u001b[1;32m---> 65\u001b[0m plot_signals(audio_file)\n\u001b[0;32m     67\u001b[0m \u001b[38;5;66;03m# Prepare data for LSTM model\u001b[39;00m\n\u001b[0;32m     68\u001b[0m X \u001b[38;5;241m=\u001b[39m prepare_data(audio_file)\n",
      "Cell \u001b[1;32mIn[27], line 41\u001b[0m, in \u001b[0;36mplot_signals\u001b[1;34m(audio_file)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot_signals\u001b[39m(audio_file):\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;66;03m# Load the recorded speech signal\u001b[39;00m\n\u001b[1;32m---> 41\u001b[0m     y, sr \u001b[38;5;241m=\u001b[39m librosa\u001b[38;5;241m.\u001b[39mload(audio_file, sr\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     43\u001b[0m     \u001b[38;5;66;03m# Plot the waveform\u001b[39;00m\n\u001b[0;32m     44\u001b[0m     plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\librosa\\core\\audio.py:183\u001b[0m, in \u001b[0;36mload\u001b[1;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path, (\u001b[38;5;28mstr\u001b[39m, pathlib\u001b[38;5;241m.\u001b[39mPurePath)):\n\u001b[0;32m    180\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    181\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPySoundFile failed. Trying audioread instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m\n\u001b[0;32m    182\u001b[0m     )\n\u001b[1;32m--> 183\u001b[0m     y, sr_native \u001b[38;5;241m=\u001b[39m __audioread_load(path, offset, duration, dtype)\n\u001b[0;32m    184\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    185\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\decorator.py:232\u001b[0m, in \u001b[0;36mdecorate.<locals>.fun\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kwsyntax:\n\u001b[0;32m    231\u001b[0m     args, kw \u001b[38;5;241m=\u001b[39m fix(args, kw, sig)\n\u001b[1;32m--> 232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m caller(func, \u001b[38;5;241m*\u001b[39m(extras \u001b[38;5;241m+\u001b[39m args), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\librosa\\util\\decorators.py:59\u001b[0m, in \u001b[0;36mdeprecated.<locals>.__wrapper\u001b[1;34m(func, *args, **kwargs)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Warn the user, and then proceed.\"\"\"\u001b[39;00m\n\u001b[0;32m     51\u001b[0m warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m     52\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{:s}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{:s}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mDeprecated as of librosa version \u001b[39m\u001b[38;5;132;01m{:s}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     53\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mIt will be removed in librosa version \u001b[39m\u001b[38;5;132;01m{:s}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     57\u001b[0m     stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,  \u001b[38;5;66;03m# Would be 2, but the decorator adds a level\u001b[39;00m\n\u001b[0;32m     58\u001b[0m )\n\u001b[1;32m---> 59\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\librosa\\core\\audio.py:239\u001b[0m, in \u001b[0;36m__audioread_load\u001b[1;34m(path, offset, duration, dtype)\u001b[0m\n\u001b[0;32m    236\u001b[0m     reader \u001b[38;5;241m=\u001b[39m path\n\u001b[0;32m    237\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    238\u001b[0m     \u001b[38;5;66;03m# If the input was not an audioread object, try to open it\u001b[39;00m\n\u001b[1;32m--> 239\u001b[0m     reader \u001b[38;5;241m=\u001b[39m audioread\u001b[38;5;241m.\u001b[39maudio_open(path)\n\u001b[0;32m    241\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m reader \u001b[38;5;28;01mas\u001b[39;00m input_file:\n\u001b[0;32m    242\u001b[0m     sr_native \u001b[38;5;241m=\u001b[39m input_file\u001b[38;5;241m.\u001b[39msamplerate\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\audioread\\__init__.py:127\u001b[0m, in \u001b[0;36maudio_open\u001b[1;34m(path, backends)\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m BackendClass \u001b[38;5;129;01min\u001b[39;00m backends:\n\u001b[0;32m    126\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 127\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m BackendClass(path)\n\u001b[0;32m    128\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m DecodeError:\n\u001b[0;32m    129\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\audioread\\rawread.py:59\u001b[0m, in \u001b[0;36mRawAudioFile.__init__\u001b[1;34m(self, filename)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, filename):\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fh \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(filename, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     62\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file \u001b[38;5;241m=\u001b[39m aifc\u001b[38;5;241m.\u001b[39mopen(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fh)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'speech_processing.wav'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import librosa.display\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Bidirectional, Dense, TimeDistributed, Dropout\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def prepare_data(audio_file):\n",
    "    # Load the recorded speech signal\n",
    "    y, sr = librosa.load(audio_file, sr=None)\n",
    "\n",
    "    # Preprocessing\n",
    "    # Short-Time Fourier Transform (STFT)\n",
    "    D = np.abs(librosa.stft(y))\n",
    "\n",
    "    # Mel-Frequency Cepstral Coefficients (MFCC)\n",
    "    mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
    "\n",
    "    # Prepare input data for the LSTM model\n",
    "    X = mfccs.T  # Transpose the MFCC matrix to match the shape expected by the LSTM model\n",
    "    X = X.reshape(X.shape[0], X.shape[1], 1)  # Add channel dimension\n",
    "\n",
    "    return X\n",
    "\n",
    "def build_lstm_model(input_shape, num_classes):\n",
    "    model = Sequential([\n",
    "        Bidirectional(LSTM(units=128, return_sequences=True), input_shape=input_shape),\n",
    "        TimeDistributed(Dense(units=64, activation='relu')),\n",
    "        Dropout(0.2),\n",
    "        Bidirectional(LSTM(units=64, return_sequences=True)),\n",
    "        TimeDistributed(Dense(units=num_classes, activation='softmax'))\n",
    "    ])\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "def plot_signals(audio_file):\n",
    "    # Load the recorded speech signal\n",
    "    y, sr = librosa.load(audio_file, sr=None)\n",
    "\n",
    "    # Plot the waveform\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.plot(np.arange(len(y)) / sr, y)\n",
    "    plt.title('Waveform')\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.ylabel('Amplitude')\n",
    "\n",
    "    # Plot the spectrogram\n",
    "    plt.subplot(2, 1, 2)\n",
    "    D = np.abs(librosa.stft(y))\n",
    "    librosa.display.specshow(librosa.amplitude_to_db(D, ref=np.max), sr=sr, x_axis='time', y_axis='log')\n",
    "    plt.colorbar(format='%+2.0f dB')\n",
    "    plt.title('Spectrogram')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Define the audio file path\n",
    "audio_file = \"speech_processing.wav\"\n",
    "\n",
    "# Plot the signals\n",
    "plot_signals(audio_file)\n",
    "\n",
    "# Prepare data for LSTM model\n",
    "X = prepare_data(audio_file)\n",
    "\n",
    "# Define the number of classes (replace with actual number)\n",
    "num_classes = 10\n",
    "\n",
    "# Build LSTM model\n",
    "model = build_lstm_model(input_shape=X.shape[1:], num_classes=num_classes)\n",
    "\n",
    "# Display model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df27e4e-9bbd-40cc-bcce-fbdd501cb41a",
   "metadata": {},
   "source": [
    "#### Question-2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc8b6e0-0dfa-4ac4-82c9-cbd5fde50368",
   "metadata": {},
   "source": [
    " *A2. Speak the sentence “Bhanumathi weds Rajat” (भानुमति वेड्स रजि || భానుమతి వెడ్స్ రజత్). \n",
    "Construct speech for the word “Bharat” (భారత్ || भारत  || ಭರತ್ || பாரத்) by combinin \n",
    "segmented phonemes taken from “Bhanumathi weds Rajat” speech recording. Listen to this wo d\n",
    "speech generated a nd note down the issues associated with this approach of speech synthesis.  he\n",
    "string written Indian scripts may have some error. Please valid\n",
    "ate before u*sing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f08604-c30d-4679-8643-a2cca00be617",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tempfile\n",
    "import speech_recognition as sr\n",
    "import pyttsx3\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import librosa\n",
    "\n",
    "# Get a temporary directory where you have write permissions\n",
    "custom_temp_dir =  \"Documents/AI in speech processing\"\n",
    "\n",
    "# Function to segment phonemes for a target word in transcription\n",
    "def segment_phonemes(transcription, target_word):\n",
    "    words = transcription.split()\n",
    "    for word in words:\n",
    "        if word.lower() == target_word.lower():\n",
    "            return word\n",
    "\n",
    "# Function to synthesize speech for a word using segmented phonemes\n",
    "def synthesize_word(phonemes, output_file):\n",
    "    engine = pyttsx3.init()\n",
    "    engine.save_to_file(phonemes, output_file)\n",
    "    engine.runAndWait()\n",
    "\n",
    "# Transcribe the audio file\n",
    "audio_file = \"speech_processing_somesh.wav\"\n",
    "recognizer = sr.Recognizer()\n",
    "with sr.AudioFile(audio_file) as source:\n",
    "    audio_data = recognizer.record(source)\n",
    "transcription = recognizer.recognize_google(audio_data)\n",
    "\n",
    "# Segment phonemes for the word \"Bharat\"\n",
    "phonemes = segment_phonemes(transcription, \"somesh\")\n",
    "\n",
    "# Synthesize speech for the word \"Bharat\"\n",
    "output_file = os.path.join(custom_temp_dir, \"speech_processing_somesh.wav\")\n",
    "synthesize_word(phonemes, output_file)\n",
    "\n",
    "# Plot original and reconstructed signals\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Original signal\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.title('Original Signal')\n",
    "audio_data_np, _ = librosa.load(audio_file, sr=source.SAMPLE_RATE)\n",
    "plt.plot(np.linspace(0, len(audio_data_np) / source.SAMPLE_RATE, num=len(audio_data_np)), audio_data_np)\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Amplitude')\n",
    "\n",
    "# Reconstructed signal\n",
    "reconstructed_audio_data, _ = librosa.load(output_file, sr=source.SAMPLE_RATE)\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.title('Reconstructed Signal')\n",
    "plt.plot(np.linspace(0, len(reconstructed_audio_data) / source.SAMPLE_RATE, num=len(reconstructed_audio_data)), reconstructed_audio_data)\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Amplitude')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373b1c30-9c6a-4cf4-a42b-cac31ee6b6fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53971677-2375-40b5-ade9-54c979f46153",
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython.display as ipd \n",
    "ipd.display(ipd.Audio(r\"C:\\Users\\Akhileswar\\Documents\\AI in Speech Processing\\speech_processing_somesh.wav\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855e6425-c65a-426d-bd8d-f5bbe6868d36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e711a8-d242-4f6d-bf6d-45092adbb942",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
